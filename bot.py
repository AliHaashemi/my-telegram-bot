import os
import requests
import torch
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from supabase import create_client, Client
from transformers import AutoModelForCausalLM, AutoTokenizer

# ==================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ ====================
BOT_TOKEN = os.environ.get('BOT_TOKEN')  # ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
HF_TOKEN = os.environ.get('HF_TOKEN')    # ØªÙˆÚ©Ù† Hugging Face
SUPABASE_URL = os.environ.get('SUPABASE_URL')  # URL Ø³ÙˆÙ¾Ø§Ø¨ÛŒØ³
SUPABASE_KEY = os.environ.get('SUPABASE_KEY')  # ØªÙˆÚ©Ù† API Ø³ÙˆÙ¾Ø§Ø¨ÛŒØ³

# ==================== Ø¨Ø±Ø±Ø³ÛŒ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ ====================
if not all([BOT_TOKEN, HF_TOKEN, SUPABASE_URL, SUPABASE_KEY]):
    raise ValueError("Ù„Ø·ÙØ§Ù‹ Ù‡Ù…Ù‡ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†ÛŒØ¯")

# ==================== Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øªâ€ŒÙ‡Ø§ ====================
# Ø³ÙˆÙ¾Ø§Ø¨ÛŒØ³
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ StepFun
try:
    print("ğŸŒ€ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ StepFun...")
    model = AutoModelForCausalLM.from_pretrained(
        "stepfun-ai/Step-Audio-2-mini", 
        trust_remote_code=True, 
        torch_dtype="auto"
    )
    tokenizer = AutoTokenizer.from_pretrained("stepfun-ai/Step-Audio-2-mini")
    print("âœ… Ù…Ø¯Ù„ StepFun Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {e}")
    model = None
    tokenizer = None

# ==================== ØªÙˆØ§Ø¨Ø¹ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ ====================
async def save_user(user_id: int, username: str, first_name: str, last_name: str):
    """Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
    try:
        existing_user = supabase.table("users").select("*").eq("user_id", user_id).execute()
        
        if not existing_user.data:
            supabase.table("users").insert({
                "user_id": user_id,
                "username": username,
                "first_name": first_name,
                "last_name": last_name or "",
                "message_count": 0,
                "created_at": "now()"
            }).execute()
            print(f"âœ… Ú©Ø§Ø±Ø¨Ø± Ø¬Ø¯ÛŒØ¯ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {user_id}")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ø±Ø¨Ø±: {e}")

async def save_message(user_id: int, message_text: str, role: str = "user"):
    """Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
    try:
        supabase.table("messages").insert({
            "user_id": user_id,
            "message_text": message_text,
            "role": role,
            "created_at": "now()"
        }).execute()
        
        # Ø¢Ù¾Ø¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±
        supabase.table("users").update({
            "message_count": supabase.table("users")
                .select("message_count")
                .eq("user_id", user_id)
                .execute().data[0]["message_count"] + 1
        }).eq("user_id", user_id).execute()
        
        print(f"ğŸ’¾ Ù¾ÛŒØ§Ù… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± {user_id}")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù…: {e}")

async def get_user_history(user_id: int, limit: int = 6):
    """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
    try:
        response = supabase.table("messages").select("*").eq("user_id", user_id).order("created_at", desc=False).limit(limit).execute()
        return response.data
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")
        return []

# ==================== ØªÙˆØ§Ø¨Ø¹ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ ====================
def generate_stepfun_response(prompt: str, history: list = None):
    """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ StepFun AI"""
    try:
        if model is None or tokenizer is None:
            return "Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª"
        
        # Ø³Ø§Ø®Øª Ù…ØªÙ† ÙˆØ±ÙˆØ¯ÛŒ Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        if history:
            conversation = "\n".join([f"{'User' if msg['role'] == 'user' else 'Assistant'}: {msg['message_text']}" for msg in history])
            full_prompt = f"{conversation}\nUser: {prompt}\nAssistant:"
        else:
            full_prompt = f"User: {prompt}\nAssistant:"
        
        # ØªÙˆÚ©Ù†Ø§ÛŒØ² Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®
        inputs = tokenizer.encode(full_prompt, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model.generate(
                inputs,
                max_length=500,
                temperature=0.7,
                do_sample=True,
                pad_token_id=tokenizer.eos_token_id
            )
        
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ù¾Ø§Ø³Ø® Ø¢Ø®Ø±
        if "Assistant:" in response:
            response = response.split("Assistant:")[-1].strip()
        
        return response
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {e}")
        return "Ù…ØªØ£Ø³ÙÙ…ØŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯"

def generate_huggingface_response(prompt: str):
    """ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ Hugging Face (fallback)"""
    try:
        url = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium"
        headers = {"Authorization": f"Bearer {HF_TOKEN}"}
        data = {"inputs": prompt, "parameters": {"max_length": 100}}
        
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                return result[0].get('generated_text', 'Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…')
        return "Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…"
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„: {str(e)}"

# =================â• Ø¯Ø³ØªÙˆØ±Ø§Øª Ø±Ø¨Ø§Øª ====================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø¯Ø³ØªÙˆØ± Ø´Ø±ÙˆØ¹"""
    user = update.effective_user
    await save_user(user.id, user.username, user.first_name, user.last_name)
    
    welcome_text = (
        "ğŸ‘‹ Ø³Ù„Ø§Ù…! Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!\n\n"
        "Ù…Ù† Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ StepFun Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù… Ùˆ Ø­Ø§ÙØ¸Ù‡ Ø¯Ø§Ø±Ù…!\n"
        "Ù‡Ø± Ù¾ÛŒØ§Ù…ÛŒ Ø¨ÙØ±Ø³ØªÛŒØ¯ Ø¨Ø§ ØªÙˆØ¬Ù‡ Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù…."
    )
    await update.message.reply_text(welcome_text)
    await save_message(user.id, "/start", "command")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    user = update.effective_user
    user_text = update.message.text
    
    print(f"ğŸ“© Ù¾ÛŒØ§Ù… Ø§Ø² {user.id}: {user_text}")
    
    # Ø°Ø®ÛŒØ±Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
    await save_user(user.id, user.username, user.first_name, user.last_name)
    
    await update.message.reply_chat_action("typing")
    
    try:
        # Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±
        history = await get_user_history(user.id)
        print(f"ğŸ“– ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±: {len(history)} Ù¾ÛŒØ§Ù…")
        
        # ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ StepFun
        bot_response = generate_stepfun_response(user_text, history)
        
        # Ø§Ú¯Ø± StepFun Ø¬ÙˆØ§Ø¨ Ù†Ø¯Ø§Ø¯ØŒ Ø§Ø² Hugging Face Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if not bot_response or "Ù¾Ø§Ø³Ø® Ù†Ø§Ù…Ø¹Ù„ÙˆÙ…" in bot_response:
            bot_response = generate_huggingface_response(user_text)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ùˆ Ù¾Ø§Ø³Ø® Ø±Ø¨Ø§Øª
        await save_message(user.id, user_text, "user")
        await save_message(user.id, bot_response, "assistant")
        
        await update.message.reply_text(bot_response[:4000])
        
    except Exception as e:
        error_msg = f"Ø®Ø·Ø§: {str(e)}"
        print(f"ğŸš¨ Ø®Ø·Ø§: {error_msg}")
        await update.message.reply_text("âš¡ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø¢Ù…Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.")

async def history_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ù…Ø´Ø§Ù‡Ø¯Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡"""
    user = update.effective_user
    history = await get_user_history(user.id, 10)
    
    response = "ğŸ“– Ø¢Ø®Ø±ÛŒÙ† Ú¯ÙØªÚ¯ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø§:\n\n"
    for msg in history[-5:]:  # ÙÙ‚Ø· Ûµ ØªØ§ Ø¢Ø®Ø±
        role_icon = "ğŸ‘¤" if msg['role'] == 'user' else "ğŸ¤–"
        response += f"{role_icon} {msg['message_text']}\n"
        response += "â”€" * 30 + "\n"
    
    await update.message.reply_text(response[:4000])

async def stats_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±"""
    user = update.effective_user
    try:
        user_data = supabase.table("users").select("*").eq("user_id", user.id).execute()
        if user_data.data:
            msg_count = user_data.data[0]["message_count"]
            await update.message.reply_text(f"ğŸ“Š Ø´Ù…Ø§ {msg_count} Ù¾ÛŒØ§Ù… ÙØ±Ø³ØªØ§Ø¯ÛŒØ¯!")
    except Exception as e:
        await update.message.reply_text(f"âŒ Ø®Ø·Ø§: {str(e)}")

# ==================== Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª ====================
def main():
    application = Application.builder().token(BOT_TOKEN).build()
    
    # Ø¯Ø³ØªÙˆØ±Ø§Øª
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("history", history_cmd))
    application.add_handler(CommandHandler("stats", stats_cmd))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    print("ğŸš€ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ú©Ø±Ø¯!")
    print("ğŸ“Š Ù‡Ù…Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¯Ø± Supabase Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯")
    print("ğŸ§  Ø§Ø² Ù…Ø¯Ù„ StepFun AI Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
    
    application.run_polling()

if __name__ == '__main__':
    main()
